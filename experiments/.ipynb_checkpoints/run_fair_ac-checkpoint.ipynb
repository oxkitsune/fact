{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed66bcd-8d89-4c60-988d-0d200efca8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import base_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22abca88-3942-47d6-88a1-eec4d44cda81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directories:\n",
      "root_dir: /home/fact21/fact_refactor\n",
      "data_dir: /home/fact21/fact_refactor/dataset/NBA\n",
      "model_dir: /home/fact21/fact_refactor/experiments/fair_ac/logs/nba/nba_fair_ac_main_40_lambda1_1.0_lambda2_1.0/ac_epoch1000.pt\n",
      "========================================\n",
      "device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR, DATA_PATH, MODEL_DIR, DEVICE = base_experiment.setup_evaluation(\n",
    "    seed=42,\n",
    "    data_path=\"dataset/NBA\",\n",
    "    model_dir=\"experiments/fair_ac/logs/nba/nba_fair_ac_main_40_lambda1_1.0_lambda2_1.0/ac_epoch1000.pt\",\n",
    "    device=2\n",
    ")\n",
    "\n",
    "# after we set up the experiment, we can import the rest\n",
    "from dataset import NBA\n",
    "from models.ac import FairAC, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c522bf40-9656-4885-a217-e24fb3d1373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 403 nodes and 21645 edges\n",
      "Using feat_drop_rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "dataset = NBA(\n",
    "    nodes_path=DATA_PATH / \"nba.csv\",\n",
    "    edges_path=DATA_PATH / \"nba_relationship.txt\",\n",
    "    embedding_path=DATA_PATH / \"nba_embedding10.npy\",\n",
    "    feat_drop_rate=0.3,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Loaded dataset with {dataset.graph.num_nodes()} nodes and {dataset.graph.num_edges()} edges\")\n",
    "print(f\"Using feat_drop_rate: {dataset.feat_drop_rate}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7225cd57-54a4-4e11-88f7-78850548e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /home/fact21/fact_refactor/experiments/fair_ac/logs/nba/nba_fair_ac_main_40_lambda1_1.0_lambda2_1.0/ac_epoch1000.pt\n"
     ]
    }
   ],
   "source": [
    "# Load in the model\n",
    "model = torch.load(MODEL_DIR.resolve()).to(DEVICE)\n",
    "print(\"Loaded model from\", MODEL_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d65c933-d9f3-425a-a4a6-58af68c927cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FairAC trainer\n",
    "trainer = Trainer(\n",
    "    ac_model=model,\n",
    "    lambda1=1.0,\n",
    "    lambda2=1.0,\n",
    "    dataset=dataset,\n",
    "    device=DEVICE,\n",
    "    gnn_kind=\"GCN\",\n",
    "    gnn_hidden_dim=128,\n",
    "    gnn_lr=1e-3,\n",
    "    gnn_weight_decay=1e-5,\n",
    "    gnn_args={\"dropout\": 0.5},\n",
    "    log_dir=MODEL_DIR.parent / \"eval/\",\n",
    "    min_acc=0.65,\n",
    "    min_roc=0.69,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8646c312-7ae4-4412-96b1-85aa862ad0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009277820587158203,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 66,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3d28c5177249188a1d815bdf85553e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (79) must match the size of tensor b (403) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_with_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurr_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fact_refactor/src/models/ac/_trainer.py:293\u001b[0m, in \u001b[0;36mTrainer._eval_with_gnn\u001b[0;34m(self, curr_epoch, epochs, progress_bar)\u001b[0m\n\u001b[1;32m    285\u001b[0m roc_test \u001b[38;5;241m=\u001b[39m roc_auc_score(\n\u001b[1;32m    286\u001b[0m     labels[test_idx]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    287\u001b[0m     output[test_idx]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    288\u001b[0m )\n\u001b[1;32m    289\u001b[0m parity, equality \u001b[38;5;241m=\u001b[39m fair_metric(\n\u001b[1;32m    290\u001b[0m     output, test_idx, labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msens\n\u001b[1;32m    291\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m consistency \u001b[38;5;241m=\u001b[39m \u001b[43mconsistency_metric\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m result \u001b[38;5;241m=\u001b[39m Metrics(\n\u001b[1;32m    298\u001b[0m     curr_epoch, acc_test\u001b[38;5;241m.\u001b[39mitem(), roc_test, parity, equality, consistency\n\u001b[1;32m    299\u001b[0m )\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    302\u001b[0m     (\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_metrics\u001b[38;5;241m.\u001b[39mbest_fair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mroc \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_roc\n\u001b[1;32m    310\u001b[0m ):\n",
      "File \u001b[0;32m~/fact_refactor/src/metrics.py:45\u001b[0m, in \u001b[0;36mconsistency_metric\u001b[0;34m(adj, test_idx, y_pred_test)\u001b[0m\n\u001b[1;32m     37\u001b[0m indicators \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     38\u001b[0m     y_pred_test[test_idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mne(y_pred_test[test_idx]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     39\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# indicators = (~y_pred_test[test_idx].eq(y_pred_test[test_idx])).float()\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# for i in test_idx:\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#     for j in test_idx:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#         print(i, j, indicators[i][j], sim_scores[i][j], x_similarity[i][j])\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m numerator \u001b[38;5;241m=\u001b[39m (\u001b[43mindicators\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_similarity\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     46\u001b[0m denominator \u001b[38;5;241m=\u001b[39m sim_scores\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     48\u001b[0m consistency \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m numerator \u001b[38;5;241m/\u001b[39m denominator\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (79) must match the size of tensor b (403) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "trainer._eval_with_gnn(curr_epoch=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
