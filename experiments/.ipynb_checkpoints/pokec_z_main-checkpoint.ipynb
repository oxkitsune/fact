{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36490633-6b99-4cda-bbf8-6fba5ebefb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directories:\n",
      "root_dir: /home/fact21/fact_refactor\n",
      "data_dir: /home/fact21/fact_refactor/dataset/pokec\n",
      "log_dir: /home/fact21/fact_refactor/experiments/logs/pokec_z\n",
      "========================================\n",
      "device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "import base_experiment\n",
    "\n",
    "ROOT_DIR, DATA_PATH, LOG_DIR, DEVICE = base_experiment.setup_experiment(\n",
    "    seed=20, \n",
    "    data_path=\"dataset/pokec\", \n",
    "    log_dir=\"experiments/logs/pokec_z\", \n",
    "    device=1\n",
    ")\n",
    "\n",
    "# import these after, as we need to set correct path in setup_experiment\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.ac import FairAC, Trainer\n",
    "from dataset import PokecZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85528069-1cf2-4e5a-8d97-56fde897e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0\n",
      "index:  1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 4.28 GiB (GPU 1; 23.64 GiB total capacity; 17.96 GiB already allocated; 1.62 GiB free; 21.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load in the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPokecZ\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregion_job.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43medges_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mregion_job_relationship.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_PATH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpokec_z_embedding10.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeat_drop_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded dataset with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnum_nodes()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m nodes and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mnum_edges()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m edges\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing feat_drop_rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mfeat_drop_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/fact_refactor/src/dataset.py:309\u001b[0m, in \u001b[0;36mPokecZ.__init__\u001b[0;34m(self, nodes_path, edges_path, embedding_path, feat_drop_rate, device, sens_attr, predict_attr, label_number, sens_number, sample_number, test_idx, normalize_features, data_seed)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    295\u001b[0m     nodes_path: Path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     data_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    308\u001b[0m ):\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_drop_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43msens_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredict_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43msens_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalize_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fact_refactor/src/dataset.py:153\u001b[0m, in \u001b[0;36mFairACDataset.__init__\u001b[0;34m(self, nodes_path, edges_path, embedding_path, feat_drop_rate, sens_attr, predict_attr, label_number, sens_number, sample_number, test_idx, normalize_features, data_seed, device)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_drop_indices\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(drop_indices, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex: \u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_adjs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m[\u001b[49m\u001b[43msub_node\u001b[49m\u001b[43m]\u001b[49m[:, sub_node][:, keep_indices])\n\u001b[1;32m    155\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(adj\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m    156\u001b[0m mask[train_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 4.28 GiB (GPU 1; 23.64 GiB total capacity; 17.96 GiB already allocated; 1.62 GiB free; 21.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "dataset = PokecZ(\n",
    "    nodes_path=DATA_PATH / \"region_job.csv\",\n",
    "    edges_path=DATA_PATH / \"region_job_relationship.txt\",\n",
    "    embedding_path=DATA_PATH / \"pokec_z_embedding10.npy\",\n",
    "    feat_drop_rate=0.3,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Loaded dataset with {dataset.graph.num_nodes()} nodes and {dataset.graph.num_edges()} edges\")\n",
    "print(f\"Using feat_drop_rate: {dataset.feat_drop_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8048c63-8ab5-4df1-9a3a-690b9b7a7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FairAC model\n",
    "fair_ac = FairAC(\n",
    "    feature_dim=dataset.features.shape[1],\n",
    "    transformed_feature_dim=128,\n",
    "    emb_dim=dataset.embeddings.shape[1],\n",
    "    attn_vec_dim=128,\n",
    "    attn_num_heads=1,\n",
    "    dropout=0.5,\n",
    "    num_sensitive_classes=1,\n",
    ")\n",
    "\n",
    "print(f\"Created FairAC model with {1} sensitive class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da444a-ddb7-4f23-88c0-1b7374308b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FairAC trainer\n",
    "trainer = Trainer(\n",
    "    ac_model=fair_ac,\n",
    "    lambda1=1.0,\n",
    "    lambda2=1.0,\n",
    "    dataset=dataset,\n",
    "    device=DEVICE,\n",
    "    gnn_kind=\"GCN\",\n",
    "    gnn_hidden_dim=128,\n",
    "    gnn_lr=1e-3,\n",
    "    gnn_weight_decay=1e-5,\n",
    "    gnn_args={\"dropout\": 0.5},\n",
    "    log_dir=LOG_DIR,\n",
    "    min_acc=0.65,\n",
    "    min_roc=0.69,\n",
    ")\n",
    "\n",
    "print(f\"Created trainer with {'GCN'} model, using LOG_DIR: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e5949-c346-47e9-9db6-209b529795f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run pre-training\n",
    "trainer.pretrain(epochs=200)\n",
    "print(\"Finished pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52df54-5a2d-43d5-b783-e7e172f6c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop, with GNN validation\n",
    "trainer.train(val_start_epoch=800, val_epoch_interval=200, epochs=2800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
