{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36490633-6b99-4cda-bbf8-6fba5ebefb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using directories:\n",
      "root_dir: /home/fact21/fact_refactor\n",
      "data_dir: /home/fact21/fact_refactor/dataset/NBA\n",
      "log_dir: /home/fact21/fact_refactor/experiments/logs/pokec_z\n",
      "========================================\n",
      "device: cuda:2\n"
     ]
    }
   ],
   "source": [
    "import base_experiment\n",
    "\n",
    "ROOT_DIR, DATA_PATH, LOG_DIR, DEVICE = base_experiment.setup_experiment(\n",
    "    seed=20, \n",
    "    data_path=\"dataset/NBA\", \n",
    "    log_dir=\"experiments/fair_ac/logs/pokec_z\", \n",
    "    device=2\n",
    ")\n",
    "\n",
    "# import these after, as we need to set correct path in setup_experiment\n",
    "import torch\n",
    "import numpy as np\n",
    "from models.ac import FairAC, Trainer\n",
    "from dataset import NBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85528069-1cf2-4e5a-8d97-56fde897e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fact21/fact_refactor/src/dataset.py:153: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 403 nodes and 21645 edges\n",
      "Using feat_drop_rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "dataset = NBA(\n",
    "    nodes_path=DATA_PATH / \"nba.csv\",\n",
    "    edges_path=DATA_PATH / \"nba_relationship.txt\",\n",
    "    embedding_path=DATA_PATH / \"nba_embedding10.npy\",\n",
    "    feat_drop_rate=0.3,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Loaded dataset with {dataset.graph.num_nodes()} nodes and {dataset.graph.num_edges()} edges\")\n",
    "print(f\"Using feat_drop_rate: {dataset.feat_drop_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8048c63-8ab5-4df1-9a3a-690b9b7a7f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created FairAC model with 1 sensitive class\n"
     ]
    }
   ],
   "source": [
    "# Create FairAC model\n",
    "fair_ac = FairAC(\n",
    "    feature_dim=dataset.features.shape[1],\n",
    "    transformed_feature_dim=128,\n",
    "    emb_dim=dataset.embeddings.shape[1],\n",
    "    attn_vec_dim=128,\n",
    "    attn_num_heads=1,\n",
    "    dropout=0.5,\n",
    "    num_sensitive_classes=1,\n",
    ")\n",
    "\n",
    "print(f\"Created FairAC model with {1} sensitive class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08da444a-ddb7-4f23-88c0-1b7374308b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created trainer with GCN model, using LOG_DIR: /home/fact21/fact_refactor/experiments/logs/pokec_z\n"
     ]
    }
   ],
   "source": [
    "# Create FairAC trainer\n",
    "trainer = Trainer(\n",
    "    ac_model=fair_ac,\n",
    "    lambda1=1.0,\n",
    "    lambda2=1.0,\n",
    "    dataset=dataset,\n",
    "    device=DEVICE,\n",
    "    gnn_kind=\"GCN\",\n",
    "    gnn_hidden_dim=128,\n",
    "    gnn_lr=1e-3,\n",
    "    gnn_weight_decay=1e-5,\n",
    "    gnn_args={\"dropout\": 0.5},\n",
    "    log_dir=LOG_DIR,\n",
    "    min_acc=0.65,\n",
    "    min_roc=0.69,\n",
    ")\n",
    "\n",
    "print(f\"Created trainer with {'GCN'} model, using LOG_DIR: {LOG_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d33e5949-c346-47e9-9db6-209b529795f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017155885696411133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 66,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 200,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009959e9885f4011bf9b323d263ec278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished pretraining\n"
     ]
    }
   ],
   "source": [
    "# Run pre-training\n",
    "trainer.pretrain(epochs=200)\n",
    "print(\"Finished pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb52df54-5a2d-43d5-b783-e7e172f6c463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005598306655883789,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 66,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2800,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae05af3c23f1445d846ae3b761d71fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008004188537597656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 66,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006876945495605469,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 66,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9c19424b75459eb2bb44a36be08ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Main training loop, with GNN validation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_start_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m800\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_epoch_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2800\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/fact_refactor/src/models/ac/_trainer.py:233\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, epochs, val_start_epoch, val_epoch_interval, progress_bar)\u001b[0m\n\u001b[1;32m    226\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss AC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_ac\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss Reconstruction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_reconstruction\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss Sensitive: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(Csen_adv_loss \u001b[38;5;241m-\u001b[39m Csen_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    228\u001b[0m     )\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    231\u001b[0m         epoch \u001b[38;5;241m>\u001b[39m val_start_epoch \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m val_epoch_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    232\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_with_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_metrics\u001b[38;5;241m.\u001b[39mbest_fair\u001b[38;5;241m.\u001b[39macc \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_acc\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_metrics\u001b[38;5;241m.\u001b[39mbest_fair\u001b[38;5;241m.\u001b[39mroc \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_roc\n\u001b[1;32m    238\u001b[0m ):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease set smaller acc/roc thresholds!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/fact_refactor/src/models/ac/_trainer.py:308\u001b[0m, in \u001b[0;36mTrainer._eval_with_gnn\u001b[0;34m(self, curr_epoch, epochs, progress_bar)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    306\u001b[0m     test_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtest_idx\n\u001b[0;32m--> 308\u001b[0m     _, output \u001b[38;5;241m=\u001b[39m \u001b[43mgnn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     acc_test \u001b[38;5;241m=\u001b[39m accuracy(output[test_idx], labels[test_idx])\n\u001b[1;32m    311\u001b[0m     roc_test \u001b[38;5;241m=\u001b[39m roc_auc_score(\n\u001b[1;32m    312\u001b[0m         labels[test_idx]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    313\u001b[0m         output[test_idx]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m    314\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/fairAC/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/fact_refactor/src/models/gnn/__init__.py:67\u001b[0m, in \u001b[0;36mWrappedGNN.forward\u001b[0;34m(self, g, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, g, x):\n\u001b[0;32m---> 67\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(z)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z, y\n",
      "File \u001b[0;32m~/miniconda3/envs/fairAC/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/fact_refactor/src/models/gnn/_gcn.py:45\u001b[0m, in \u001b[0;36mGCNBody.forward\u001b[0;34m(self, g, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgc1(g, x))\n\u001b[1;32m     44\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n\u001b[0;32m---> 45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgc2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# x = self.dropout(x)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/fairAC/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/fairAC/lib/python3.8/site-packages/dgl/nn/pytorch/conv/graphconv.py:407\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    405\u001b[0m         norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m degs\n\u001b[1;32m    406\u001b[0m     shp \u001b[38;5;241m=\u001b[39m norm\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m,) \u001b[38;5;241m*\u001b[39m (feat_src\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 407\u001b[0m     norm \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m     feat_src \u001b[38;5;241m=\u001b[39m feat_src \u001b[38;5;241m*\u001b[39m norm\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Main training loop, with GNN validation\n",
    "trainer.train(val_start_epoch=800, val_epoch_interval=200, epochs=2800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
