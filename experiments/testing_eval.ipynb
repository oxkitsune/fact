{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed66bcd-8d89-4c60-988d-0d200efca8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import base_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22abca88-3942-47d6-88a1-eec4d44cda81",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Model file couldn't be resolved! Ensure it exists!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ROOT_DIR, DATA_PATH, MODEL_DIR, DEVICE \u001b[38;5;241m=\u001b[39m \u001b[43mbase_experiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_evaluation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m34\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset/NBA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiments/fair_ac/logs/nba_testing/nba_fair_ac_main_40_lambda1_1.0_lambda2_1.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# after we set up the experiment, we can import the rest\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NBA\n",
      "File \u001b[0;32m~/fact_refactor/experiments/base_experiment.py:108\u001b[0m, in \u001b[0;36msetup_evaluation\u001b[0;34m(seed, data_path, model_dir, device)\u001b[0m\n\u001b[1;32m    106\u001b[0m data_path \u001b[38;5;241m=\u001b[39m root_dir \u001b[38;5;241m/\u001b[39m data_path\n\u001b[1;32m    107\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m root_dir \u001b[38;5;241m/\u001b[39m model_dir\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model_dir\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel file couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be resolved! Ensure it exists!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Model file couldn't be resolved! Ensure it exists!"
     ]
    }
   ],
   "source": [
    "ROOT_DIR, DATA_PATH, MODEL_DIR, DEVICE = base_experiment.setup_evaluation(\n",
    "    seed=34,\n",
    "    data_path=\"dataset/NBA\",\n",
    "    model_dir=\"experiments/fair_ac/logs/nba_testing/nba_fair_ac_main_40_lambda1_1.0_lambda2_1.0\",\n",
    "    device=2\n",
    ")\n",
    "\n",
    "# after we set up the experiment, we can import the rest\n",
    "from dataset import NBA\n",
    "from models.fair.ac import FairAC, Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c522bf40-9656-4885-a217-e24fb3d1373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 403 nodes and 21645 edges\n",
      "Using feat_drop_rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "# Load in the dataset\n",
    "dataset = NBA(\n",
    "    nodes_path=DATA_PATH / \"nba.csv\",\n",
    "    edges_path=DATA_PATH / \"nba_relationship.txt\",\n",
    "    embedding_path=DATA_PATH / \"nba_embedding10.npy\",\n",
    "    feat_drop_rate=0.3,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Loaded dataset with {dataset.graph.num_nodes()} nodes and {dataset.graph.num_edges()} edges\")\n",
    "print(f\"Using feat_drop_rate: {dataset.feat_drop_rate}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7225cd57-54a4-4e11-88f7-78850548e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model FairAC(\n",
      "  (ae): FairACAutoEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Linear(in_features=95, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=95, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (hgnn_ac): HGNNAC(\n",
      "    (attention_0): _AttentionLayer(\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      "  (sensitive_classifier): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create evaluation\n",
    "evaluation = Evaluation(\n",
    "    dataset=dataset,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "evaluation.load_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d65c933-d9f3-425a-a4a6-58af68c927cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9816, -0.9979, -0.9954,  0.2268, -0.9463, -0.0992, -0.0378, -0.1478,\n",
      "        -0.9785, -0.9427, -0.9704, -0.9967, -0.3788, -0.9833, -0.3518, -0.9980,\n",
      "         0.2218, -0.9861, -0.9820, -0.1603,  0.0106, -0.9961, -0.9904, -0.9951,\n",
      "        -0.9694, -0.9839, -0.9397, -0.9942, -0.9888,  0.2287, -0.8951, -0.9859,\n",
      "        -0.9896, -0.9710, -0.3649, -0.9452, -0.9962, -0.9852, -0.9355, -0.4345,\n",
      "        -0.9898, -0.9912, -0.0269, -0.1814, -0.9909, -0.1173, -0.3637, -0.1039,\n",
      "        -0.0331, -0.3606, -0.8888, -0.1466, -0.9590, -0.1654, -0.9341, -0.9627,\n",
      "        -0.9630, -0.9772, -0.9463, -0.1502, -0.9808, -0.8846,  0.2649, -0.9432,\n",
      "        -0.3555,  0.0705, -0.9865, -0.9802, -0.9899, -0.9722, -0.9637, -0.9955,\n",
      "        -0.8596, -0.9963, -0.9923, -0.9984, -0.9845, -0.0901, -0.9642, -0.9881,\n",
      "        -0.9894, -0.9990, -0.2526, -0.2709, -0.9811, -0.9841, -0.9673, -0.9977,\n",
      "        -0.9927, -0.9940, -0.9807, -0.0014, -0.9892, -0.9690, -0.1368, -0.9966,\n",
      "        -0.9815, -0.9311, -0.0726, -0.9695, -0.9787, -0.9913, -0.9885, -0.9958,\n",
      "        -0.9896, -0.9723, -0.9910, -0.9941, -0.9952, -0.9719, -0.9549, -0.9773,\n",
      "        -0.9784, -0.9774, -0.2362, -0.9724, -0.9896, -0.9974,  0.1890, -0.9909,\n",
      "        -0.9903, -0.9511, -0.9755, -0.9828, -0.9338, -0.9851, -0.9729, -0.9817],\n",
      "       device='cuda:2')\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008881807327270508,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2051c434cd8f42539a430a8e5ba0370e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best metrics:\n",
      "\tepoch: 541\n",
      "\tacc: 0.6709\n",
      "\troc: 0.7728\n",
      "\tparity: 0.0258, equality: 0.0056, sum: 0.0313\n",
      "\tconsistency: 0.0704\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the FairAC model\n",
    "evaluation.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c91de3-3610-497f-ac1a-442c9c9a66d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best metrics:\n",
      "\tacc: 0.7215\n",
      "\troc: 0.7978\n",
      "\tparity: 0.1319, equality: 0.0389, sum: 0.1708\n",
      "\tconsistency: 0.0704\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the FairAC model using best GNN\n",
    "evaluation.evaluate_best_gnn()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
